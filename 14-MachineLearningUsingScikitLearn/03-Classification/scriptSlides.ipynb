{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Logistic Regression"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the real world, we often come across scenarios which requires to make decisions that result into finite outcomes, like the below examples,  \n  \nWill it rain today?  \nWill I reach office on time today?  \nWould a child graduate from his/her university?  \nDoes sedentary lifestyle increase the chances to get the heart disease?  \nDoes smoking lead to lung cancer?  \nWould I wear blue, black, red outfit today?  \nWhat grade a student would get in an exam?  \nAll the above situations do reflect the input-output relationships. Here the output variable values are discrete & finite rather than continuous & infinite values like in Linear Regression. How could we model and analyze such data?  \n    \nWe could try to frame a rule which helps in guessing the outcome from the input variables. This is called a classification problem, and is an important topic in statistics and machine learning. Classification, a task of assigning objects to one of the several predefined categories, is a pervasive problem that encompasses many diverse applications in a broad array of domains. Some examples of Classification Tasks are listed below:\n    \nIn medical field, the classification task could be assigning a diagnosis to a given patient as described by observed characteristics of the patient such as age, gender, blood pressure, body mass index, presence or absence of certain symptoms, etc.  \nIn banking sector, one may want to categorize hundreds or thousands of applications for new cards containing information for several attributes such as annual salary, outstanding debts, age etc., into users who have good credit or bad credit for enabling a credit card company to do further analysis for decision making; OR one might want to learn to predict whether a particular credit card charge is legitimate or fraudulent.  \nIn social sciences, we may be interested to predict the preference of a voter for a party based on – age, income, sex, race, residence state, votes in previous elections etc.  \nIn finance sector, one would require to ascertain “whether a vendor is credit worthy”?  \nIn insurance domain, the company will need to assess “Is the submitted claim fraudulent or genuine”?  \nIn Marketing, the marketer would like to figure out “Which segment of consumers are likely to buy”?  \nMostly, in the business world, Classification problems where the response or dependent variable have discrete and finite outcomes, are more prevalent than the Regression problems where the response variable is continuous and have infinite values. Logistic Regression is one of the most common algorithm used for modeling classification problems.  "
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "* Comes under the category of supervised machine learning\n* First we should identify the boundary conditions & then the next task is to predict the target class\n* To classify gender (target class) using hair length as feature parameter\n* the idea is to predict the target class by analysis the training dataset.\n* train your model using any abvailable classification algorithms"
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": "<font color=\"red\">**Step 1:**</font> load data and run numerical and graphical summaries\n\n<font color=\"red\">**Step 2:**</font> Split the data into training data and test data\n\n<font color=\"red\">**Step 3:**</font> Fit a model using training data\n\n<font color=\"red\">**Step 3:**</font> Use a fitted model to do predictions for the test data\n\n<font color=\"red\">**Step 4:**</font> Create a confusion matrix, and compute the misclassification rate"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Imgur](https://i.imgur.com/iGNsDyl.jpg)    \n<sub>source: <a href=\"https://www.biomedware.com/files/documentation/spacestat/Statistics/Multivariate_Modeling/Regression/Implementation_of_Logistic_GWR.htm\n\" target=\"_blank\">https://www.biomedware.com/files/documentation/spacestat/Statistics/Multivariate_Modeling/Regression/Implementation_of_Logistic_GWR.htm\n</a></sub>  "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Imgur](https://i.imgur.com/WayfUZH.png)    \n<sub>source: <a href=\"https://www.saedsayad.com/logistic_regression.htm\n\" target=\"_blank\">https://www.saedsayad.com/logistic_regression.htm\n</a></sub>  "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load the packages"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n \npd.set_option(\"display.max_rows\",10)\npd.set_option(\"display.max_columns\",101)\n \n%matplotlib inline\n\n# For the evaluation\nfrom sklearn.metrics import *",
      "execution_count": 1,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n  from pandas.core import datetools\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load the data"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('data/Titanic.csv')\ndf",
      "execution_count": 2,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>",
            "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]"
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Data cleaning and manipulation and  Exploration"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "we are going to drop ‘PassengerId’, ‘Name’ and ‘Ticket’, since those variables not influence the risk of survival"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = df.drop(['PassengerId', 'Name', 'Ticket'], axis=1)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.loc[df.Cabin.isnull()]\ndf['HasCabin'] = np.nan\ndf.loc[df.Cabin.notnull(), 'HasCabin'] = 1\ndf.loc[df.Cabin.isnull(), 'HasCabin'] = 0\ndf.HasCabin.value_counts()\ndf = df.drop(['Cabin'], axis=1)\ndf\nembarked = pd.get_dummies(df.Embarked, prefix='Embarked_')\nembarked\nsex = pd.get_dummies(df.Sex, prefix='Sex_')\nsex\ndf = df.join(embarked)\ndf = df.join(sex)\ndf\nvars_to_drop = ['Sex','Embarked']\ndf = df.drop(vars_to_drop, axis=1)\ndf = df.dropna(axis=0)\ndf\ndf.to_csv('data/Titanic_Clean.csv', index=False)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Building"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = pd.read_csv('data/Titanic_Clean.csv')\ndf\nvars_to_drop = ['Sex__male','Embarked__C']\ndf = df.drop(vars_to_drop, axis=1)\ndf\ndf['_intercept'] = 1\n# Copy df across and drop Survived\nx = df\nx = x.drop('Survived', axis=1)\n \n# Set y as the survived column, we need\n# to wrap it in the dataframe to stop it\n# being series \ny = pd.DataFrame(df.Survived)\n# Make the model\nlogit = sm.Logit(y, x)\n \n# Fit the model\nresult = logit.fit()\nprint (result.summary())",
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Optimization terminated successfully.\n         Current function value: 0.441075\n         Iterations 6\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:               Survived   No. Observations:                  714\nModel:                          Logit   Df Residuals:                      704\nMethod:                           MLE   Df Model:                            9\nDate:                Wed, 25 Jul 2018   Pseudo R-squ.:                  0.3470\nTime:                        12:39:22   Log-Likelihood:                -314.93\nconverged:                       True   LL-Null:                       -482.26\n                                        LLR p-value:                 1.136e-66\n===============================================================================\n                  coef    std err          z      P>|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nPclass         -1.0132      0.197     -5.136      0.000      -1.400      -0.627\nAge            -0.0435      0.008     -5.255      0.000      -0.060      -0.027\nSibSp          -0.3634      0.129     -2.808      0.005      -0.617      -0.110\nParch          -0.0681      0.124     -0.550      0.583      -0.311       0.175\nFare            0.0008      0.002      0.332      0.740      -0.004       0.006\nHasCabin        0.5489      0.324      1.692      0.091      -0.087       1.185\nEmbarked__Q    -0.8330      0.601     -1.387      0.165      -2.010       0.344\nEmbarked__S    -0.3853      0.271     -1.420      0.155      -0.917       0.146\nSex__female     2.6527      0.223     11.910      0.000       2.216       3.089\n_intercept      2.4566      0.664      3.698      0.000       1.154       3.759\n===============================================================================\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Model Evaluation"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "pred = result.predict(x)\npred",
      "execution_count": 34,
      "outputs": [
        {
          "data": {
            "text/plain": "0      0.092604\n1      0.936340\n2      0.636565\n3      0.918227\n4      0.077030\n         ...   \n709    0.315290\n710    0.246331\n711    0.969483\n712    0.708212\n713    0.057275\nLength: 714, dtype: float64"
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "confusion_matrix(y, np.round(pred,0))",
      "execution_count": 35,
      "outputs": [
        {
          "data": {
            "text/plain": "array([[363,  61],\n       [ 80, 210]])"
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Summarize:**  \n    \n* 210 people that where predicted to survive actually survived (Correct classification)\n* 363 people that where predicted to not survive actually didn’t survive (Correct classification)\n* 61 people where predicted to survive but actually died (False Positive / Type 1 error)\n* 80 people where predicted to die but actually survived (False Negative / Type 2 error)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Support Vector Machines"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**muffin_vs_cupcake_demo.pdf:(location)**    \nhttps://notebooks.azure.com/sumendar/projects/FoundationOfStatsDSAIML-Python/tree/14-MachineLearningUsingScikitLearn/03-Classification/docs    "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Decision Tree and Random Forest\n(also covered in Ensemble learning)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.datacamp.com/community/news/how-decision-tree-model-is-different-from-random-forest-d9dyn7jqv4w  \nhttps://engmrk.com/module-13-decision-tree-and-random-forest-2/?utm_campaign=News&utm_medium=Community&utm_source=DataCamp.com"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<span style=\"color:red; font-family:Comic Sans MS\">Sources & References: </span>     \n<a href=\"https://clevertap.com/blog/a-primer-on-logistic-regression-part-i/ \" target=\"_blank\">https://clevertap.com/blog/a-primer-on-logistic-regression-part-i/ </a>  \n<a href=\"http://stamfordresearch.com/titanic-2-logistic-regression/\" target=\"_blank\">http://stamfordresearch.com/titanic-2-logistic-regression/</a>  \n<a href=\"https://github.com/adashofdata/muffin-cupcake\" target=\"_blank\">https://github.com/adashofdata/muffin-cupcake</a>  \n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}