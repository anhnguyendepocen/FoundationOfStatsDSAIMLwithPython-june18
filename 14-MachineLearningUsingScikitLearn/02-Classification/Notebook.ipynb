{
  "cells": [
    {
      "metadata": {
        "toc": true
      },
      "cell_type": "markdown",
      "source": "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Working-with-sklearn-dataset\" data-toc-modified-id=\"Working-with-sklearn-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Working with sklearn dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-and-inspect-the-breast-cancer-dataset\" data-toc-modified-id=\"Load-and-inspect-the-breast-cancer-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load and inspect the breast cancer dataset</a></span></li><li><span><a href=\"#Convert-the-dataset-into-a-pandas-Dataframe\" data-toc-modified-id=\"Convert-the-dataset-into-a-pandas-Dataframe-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Convert the dataset into a pandas Dataframe</a></span></li></ul></li><li><span><a href=\"#Applying-our-First-Model-with-Scikit-learn:-KNN\" data-toc-modified-id=\"Applying-our-First-Model-with-Scikit-learn:-KNN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Applying our First Model with Scikit-learn: KNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Splitting-into-Train-and-Test-Sets\" data-toc-modified-id=\"Splitting-into-Train-and-Test-Sets-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Splitting into Train and Test Sets</a></span></li><li><span><a href=\"#Build-our-model\" data-toc-modified-id=\"Build-our-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Build our model</a></span></li><li><span><a href=\"#Training/Fit-our-model\" data-toc-modified-id=\"Training/Fit-our-model-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Training/Fit our model</a></span></li><li><span><a href=\"#Making-Predictions\" data-toc-modified-id=\"Making-Predictions-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Making Predictions</a></span></li><li><span><a href=\"#Train-&amp;-Test-set-accuracy\" data-toc-modified-id=\"Train-&amp;-Test-set-accuracy-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Train &amp; Test set accuracy</a></span></li></ul></li><li><span><a href=\"#Improving-the-KNN-Performance-on-Cancer-Dataset\" data-toc-modified-id=\"Improving-the-KNN-Performance-on-Cancer-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Improving the KNN Performance on Cancer Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Improving-the-Model-Performance\" data-toc-modified-id=\"Improving-the-Model-Performance-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Improving the Model Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Min-Max-Scalar\" data-toc-modified-id=\"Min-Max-Scalar-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Min Max Scalar</a></span></li><li><span><a href=\"#Testing-with-different-values-of-k\" data-toc-modified-id=\"Testing-with-different-values-of-k-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Testing with different values of k</a></span></li><li><span><a href=\"#Plotting-results-of-diffrent-values-of-k\" data-toc-modified-id=\"Plotting-results-of-diffrent-values-of-k-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Plotting results of diffrent values of k</a></span></li></ul></li></ul></li><li><span><a href=\"#Understand-how-the-K-Nearest-Neighbors-(KNN)-algorithm-works\" data-toc-modified-id=\"Understand-how-the-K-Nearest-Neighbors-(KNN)-algorithm-works-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Understand how the K-Nearest Neighbors (KNN) algorithm works</a></span></li><li><span><a href=\"#Applying-our-Second-Model-with-Scikit-learn:-Logistic-Regression\" data-toc-modified-id=\"Applying-our-Second-Model-with-Scikit-learn:-Logistic-Regression-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Applying our Second Model with Scikit-learn: Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Formula\" data-toc-modified-id=\"The-Formula-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>The Formula</a></span></li><li><span><a href=\"#Evaluating-classification-models.\" data-toc-modified-id=\"Evaluating-classification-models.-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Evaluating classification models.</a></span></li></ul></li></ul></div>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Working with sklearn dataset  \n  \nFor all Data sets available with Scikit-learn, look at:  \nhttp://scikit-learn.org/stable/datasets/index.html      \n  \n**Wisconsin Breast Cancer Data Set**  \nThis is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)  "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load and inspect the breast cancer dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.datasets import load_breast_cancer\ncancer_data = load_breast_cancer()\nprint(cancer_data.DESCR)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Breast Cancer Wisconsin (Diagnostic) Database\n=============================================\n\nNotes\n-----\nData Set Characteristics:\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (\"coastline approximation\" - 1)\n\n        The mean, standard error, and \"worst\" or largest (mean of the three\n        largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n        13 is Radius SE, field 23 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\nConstruction Via Linear Programming.\" Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets\",\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\nReferences\n----------\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(cancer_data.keys())",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'target_names'])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(cancer_data.feature_names)",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n 'mean smoothness' 'mean compactness' 'mean concavity'\n 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n 'radius error' 'texture error' 'perimeter error' 'area error'\n 'smoothness error' 'compactness error' 'concavity error'\n 'concave points error' 'symmetry error' 'fractal dimension error'\n 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n 'worst smoothness' 'worst compactness' 'worst concavity'\n 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(cancer_data.data)",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n ...\n [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Convert the dataset into a pandas Dataframe "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.DataFrame(cancer_data.data,columns=cancer_data.feature_names)",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "(569, 30)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>",
            "text/plain": "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0        17.99         10.38          122.80     1001.0          0.11840   \n1        20.57         17.77          132.90     1326.0          0.08474   \n2        19.69         21.25          130.00     1203.0          0.10960   \n3        11.42         20.38           77.58      386.1          0.14250   \n4        20.29         14.34          135.10     1297.0          0.10030   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760          0.3001              0.14710         0.2419   \n1           0.07864          0.0869              0.07017         0.1812   \n2           0.15990          0.1974              0.12790         0.2069   \n3           0.28390          0.2414              0.10520         0.2597   \n4           0.13280          0.1980              0.10430         0.1809   \n\n   mean fractal dimension           ...             worst radius  \\\n0                 0.07871           ...                    25.38   \n1                 0.05667           ...                    24.99   \n2                 0.05999           ...                    23.57   \n3                 0.09744           ...                    14.91   \n4                 0.05883           ...                    22.54   \n\n   worst texture  worst perimeter  worst area  worst smoothness  \\\n0          17.33           184.60      2019.0            0.1622   \n1          23.41           158.80      1956.0            0.1238   \n2          25.53           152.50      1709.0            0.1444   \n3          26.50            98.87       567.7            0.2098   \n4          16.67           152.20      1575.0            0.1374   \n\n   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   worst fractal dimension  \n0                  0.11890  \n1                  0.08902  \n2                  0.08758  \n3                  0.17300  \n4                  0.07678  \n\n[5 rows x 30 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.describe()",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst radius</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>...</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.127292</td>\n      <td>19.289649</td>\n      <td>91.969033</td>\n      <td>654.889104</td>\n      <td>0.096360</td>\n      <td>0.104341</td>\n      <td>0.088799</td>\n      <td>0.048919</td>\n      <td>0.181162</td>\n      <td>0.062798</td>\n      <td>...</td>\n      <td>16.269190</td>\n      <td>25.677223</td>\n      <td>107.261213</td>\n      <td>880.583128</td>\n      <td>0.132369</td>\n      <td>0.254265</td>\n      <td>0.272188</td>\n      <td>0.114606</td>\n      <td>0.290076</td>\n      <td>0.083946</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.524049</td>\n      <td>4.301036</td>\n      <td>24.298981</td>\n      <td>351.914129</td>\n      <td>0.014064</td>\n      <td>0.052813</td>\n      <td>0.079720</td>\n      <td>0.038803</td>\n      <td>0.027414</td>\n      <td>0.007060</td>\n      <td>...</td>\n      <td>4.833242</td>\n      <td>6.146258</td>\n      <td>33.602542</td>\n      <td>569.356993</td>\n      <td>0.022832</td>\n      <td>0.157336</td>\n      <td>0.208624</td>\n      <td>0.065732</td>\n      <td>0.061867</td>\n      <td>0.018061</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>6.981000</td>\n      <td>9.710000</td>\n      <td>43.790000</td>\n      <td>143.500000</td>\n      <td>0.052630</td>\n      <td>0.019380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.106000</td>\n      <td>0.049960</td>\n      <td>...</td>\n      <td>7.930000</td>\n      <td>12.020000</td>\n      <td>50.410000</td>\n      <td>185.200000</td>\n      <td>0.071170</td>\n      <td>0.027290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.156500</td>\n      <td>0.055040</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.700000</td>\n      <td>16.170000</td>\n      <td>75.170000</td>\n      <td>420.300000</td>\n      <td>0.086370</td>\n      <td>0.064920</td>\n      <td>0.029560</td>\n      <td>0.020310</td>\n      <td>0.161900</td>\n      <td>0.057700</td>\n      <td>...</td>\n      <td>13.010000</td>\n      <td>21.080000</td>\n      <td>84.110000</td>\n      <td>515.300000</td>\n      <td>0.116600</td>\n      <td>0.147200</td>\n      <td>0.114500</td>\n      <td>0.064930</td>\n      <td>0.250400</td>\n      <td>0.071460</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.370000</td>\n      <td>18.840000</td>\n      <td>86.240000</td>\n      <td>551.100000</td>\n      <td>0.095870</td>\n      <td>0.092630</td>\n      <td>0.061540</td>\n      <td>0.033500</td>\n      <td>0.179200</td>\n      <td>0.061540</td>\n      <td>...</td>\n      <td>14.970000</td>\n      <td>25.410000</td>\n      <td>97.660000</td>\n      <td>686.500000</td>\n      <td>0.131300</td>\n      <td>0.211900</td>\n      <td>0.226700</td>\n      <td>0.099930</td>\n      <td>0.282200</td>\n      <td>0.080040</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>15.780000</td>\n      <td>21.800000</td>\n      <td>104.100000</td>\n      <td>782.700000</td>\n      <td>0.105300</td>\n      <td>0.130400</td>\n      <td>0.130700</td>\n      <td>0.074000</td>\n      <td>0.195700</td>\n      <td>0.066120</td>\n      <td>...</td>\n      <td>18.790000</td>\n      <td>29.720000</td>\n      <td>125.400000</td>\n      <td>1084.000000</td>\n      <td>0.146000</td>\n      <td>0.339100</td>\n      <td>0.382900</td>\n      <td>0.161400</td>\n      <td>0.317900</td>\n      <td>0.092080</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>28.110000</td>\n      <td>39.280000</td>\n      <td>188.500000</td>\n      <td>2501.000000</td>\n      <td>0.163400</td>\n      <td>0.345400</td>\n      <td>0.426800</td>\n      <td>0.201200</td>\n      <td>0.304000</td>\n      <td>0.097440</td>\n      <td>...</td>\n      <td>36.040000</td>\n      <td>49.540000</td>\n      <td>251.200000</td>\n      <td>4254.000000</td>\n      <td>0.222600</td>\n      <td>1.058000</td>\n      <td>1.252000</td>\n      <td>0.291000</td>\n      <td>0.663800</td>\n      <td>0.207500</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 30 columns</p>\n</div>",
            "text/plain": "       mean radius  mean texture  mean perimeter    mean area  \\\ncount   569.000000    569.000000      569.000000   569.000000   \nmean     14.127292     19.289649       91.969033   654.889104   \nstd       3.524049      4.301036       24.298981   351.914129   \nmin       6.981000      9.710000       43.790000   143.500000   \n25%      11.700000     16.170000       75.170000   420.300000   \n50%      13.370000     18.840000       86.240000   551.100000   \n75%      15.780000     21.800000      104.100000   782.700000   \nmax      28.110000     39.280000      188.500000  2501.000000   \n\n       mean smoothness  mean compactness  mean concavity  mean concave points  \\\ncount       569.000000        569.000000      569.000000           569.000000   \nmean          0.096360          0.104341        0.088799             0.048919   \nstd           0.014064          0.052813        0.079720             0.038803   \nmin           0.052630          0.019380        0.000000             0.000000   \n25%           0.086370          0.064920        0.029560             0.020310   \n50%           0.095870          0.092630        0.061540             0.033500   \n75%           0.105300          0.130400        0.130700             0.074000   \nmax           0.163400          0.345400        0.426800             0.201200   \n\n       mean symmetry  mean fractal dimension           ...             \\\ncount     569.000000              569.000000           ...              \nmean        0.181162                0.062798           ...              \nstd         0.027414                0.007060           ...              \nmin         0.106000                0.049960           ...              \n25%         0.161900                0.057700           ...              \n50%         0.179200                0.061540           ...              \n75%         0.195700                0.066120           ...              \nmax         0.304000                0.097440           ...              \n\n       worst radius  worst texture  worst perimeter   worst area  \\\ncount    569.000000     569.000000       569.000000   569.000000   \nmean      16.269190      25.677223       107.261213   880.583128   \nstd        4.833242       6.146258        33.602542   569.356993   \nmin        7.930000      12.020000        50.410000   185.200000   \n25%       13.010000      21.080000        84.110000   515.300000   \n50%       14.970000      25.410000        97.660000   686.500000   \n75%       18.790000      29.720000       125.400000  1084.000000   \nmax       36.040000      49.540000       251.200000  4254.000000   \n\n       worst smoothness  worst compactness  worst concavity  \\\ncount        569.000000         569.000000       569.000000   \nmean           0.132369           0.254265         0.272188   \nstd            0.022832           0.157336         0.208624   \nmin            0.071170           0.027290         0.000000   \n25%            0.116600           0.147200         0.114500   \n50%            0.131300           0.211900         0.226700   \n75%            0.146000           0.339100         0.382900   \nmax            0.222600           1.058000         1.252000   \n\n       worst concave points  worst symmetry  worst fractal dimension  \ncount            569.000000      569.000000               569.000000  \nmean               0.114606        0.290076                 0.083946  \nstd                0.065732        0.061867                 0.018061  \nmin                0.000000        0.156500                 0.055040  \n25%                0.064930        0.250400                 0.071460  \n50%                0.099930        0.282200                 0.080040  \n75%                0.161400        0.317900                 0.092080  \nmax                0.291000        0.663800                 0.207500  \n\n[8 rows x 30 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['target'] = cancer_data.target",
      "execution_count": 64,
      "outputs": []
    },
    {
      "metadata": {
        "run_control": {
          "marked": false
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['target'].value_counts()",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": "1    357\n0    212\nName: target, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cancer_data.target_names",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "array(['malignant', 'benign'], dtype='<U9')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head(20)",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean radius</th>\n      <th>mean texture</th>\n      <th>mean perimeter</th>\n      <th>mean area</th>\n      <th>mean smoothness</th>\n      <th>mean compactness</th>\n      <th>mean concavity</th>\n      <th>mean concave points</th>\n      <th>mean symmetry</th>\n      <th>mean fractal dimension</th>\n      <th>...</th>\n      <th>worst texture</th>\n      <th>worst perimeter</th>\n      <th>worst area</th>\n      <th>worst smoothness</th>\n      <th>worst compactness</th>\n      <th>worst concavity</th>\n      <th>worst concave points</th>\n      <th>worst symmetry</th>\n      <th>worst fractal dimension</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>0.07871</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.26540</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>0.05667</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.18600</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>0.05999</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.24300</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>0.09744</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.25750</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>0.05883</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.16250</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12.45</td>\n      <td>15.70</td>\n      <td>82.57</td>\n      <td>477.1</td>\n      <td>0.12780</td>\n      <td>0.17000</td>\n      <td>0.15780</td>\n      <td>0.08089</td>\n      <td>0.2087</td>\n      <td>0.07613</td>\n      <td>...</td>\n      <td>23.75</td>\n      <td>103.40</td>\n      <td>741.6</td>\n      <td>0.1791</td>\n      <td>0.5249</td>\n      <td>0.5355</td>\n      <td>0.17410</td>\n      <td>0.3985</td>\n      <td>0.12440</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>18.25</td>\n      <td>19.98</td>\n      <td>119.60</td>\n      <td>1040.0</td>\n      <td>0.09463</td>\n      <td>0.10900</td>\n      <td>0.11270</td>\n      <td>0.07400</td>\n      <td>0.1794</td>\n      <td>0.05742</td>\n      <td>...</td>\n      <td>27.66</td>\n      <td>153.20</td>\n      <td>1606.0</td>\n      <td>0.1442</td>\n      <td>0.2576</td>\n      <td>0.3784</td>\n      <td>0.19320</td>\n      <td>0.3063</td>\n      <td>0.08368</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>13.71</td>\n      <td>20.83</td>\n      <td>90.20</td>\n      <td>577.9</td>\n      <td>0.11890</td>\n      <td>0.16450</td>\n      <td>0.09366</td>\n      <td>0.05985</td>\n      <td>0.2196</td>\n      <td>0.07451</td>\n      <td>...</td>\n      <td>28.14</td>\n      <td>110.60</td>\n      <td>897.0</td>\n      <td>0.1654</td>\n      <td>0.3682</td>\n      <td>0.2678</td>\n      <td>0.15560</td>\n      <td>0.3196</td>\n      <td>0.11510</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>13.00</td>\n      <td>21.82</td>\n      <td>87.50</td>\n      <td>519.8</td>\n      <td>0.12730</td>\n      <td>0.19320</td>\n      <td>0.18590</td>\n      <td>0.09353</td>\n      <td>0.2350</td>\n      <td>0.07389</td>\n      <td>...</td>\n      <td>30.73</td>\n      <td>106.20</td>\n      <td>739.3</td>\n      <td>0.1703</td>\n      <td>0.5401</td>\n      <td>0.5390</td>\n      <td>0.20600</td>\n      <td>0.4378</td>\n      <td>0.10720</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12.46</td>\n      <td>24.04</td>\n      <td>83.97</td>\n      <td>475.9</td>\n      <td>0.11860</td>\n      <td>0.23960</td>\n      <td>0.22730</td>\n      <td>0.08543</td>\n      <td>0.2030</td>\n      <td>0.08243</td>\n      <td>...</td>\n      <td>40.68</td>\n      <td>97.65</td>\n      <td>711.4</td>\n      <td>0.1853</td>\n      <td>1.0580</td>\n      <td>1.1050</td>\n      <td>0.22100</td>\n      <td>0.4366</td>\n      <td>0.20750</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>16.02</td>\n      <td>23.24</td>\n      <td>102.70</td>\n      <td>797.8</td>\n      <td>0.08206</td>\n      <td>0.06669</td>\n      <td>0.03299</td>\n      <td>0.03323</td>\n      <td>0.1528</td>\n      <td>0.05697</td>\n      <td>...</td>\n      <td>33.88</td>\n      <td>123.80</td>\n      <td>1150.0</td>\n      <td>0.1181</td>\n      <td>0.1551</td>\n      <td>0.1459</td>\n      <td>0.09975</td>\n      <td>0.2948</td>\n      <td>0.08452</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>15.78</td>\n      <td>17.89</td>\n      <td>103.60</td>\n      <td>781.0</td>\n      <td>0.09710</td>\n      <td>0.12920</td>\n      <td>0.09954</td>\n      <td>0.06606</td>\n      <td>0.1842</td>\n      <td>0.06082</td>\n      <td>...</td>\n      <td>27.28</td>\n      <td>136.50</td>\n      <td>1299.0</td>\n      <td>0.1396</td>\n      <td>0.5609</td>\n      <td>0.3965</td>\n      <td>0.18100</td>\n      <td>0.3792</td>\n      <td>0.10480</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>19.17</td>\n      <td>24.80</td>\n      <td>132.40</td>\n      <td>1123.0</td>\n      <td>0.09740</td>\n      <td>0.24580</td>\n      <td>0.20650</td>\n      <td>0.11180</td>\n      <td>0.2397</td>\n      <td>0.07800</td>\n      <td>...</td>\n      <td>29.94</td>\n      <td>151.70</td>\n      <td>1332.0</td>\n      <td>0.1037</td>\n      <td>0.3903</td>\n      <td>0.3639</td>\n      <td>0.17670</td>\n      <td>0.3176</td>\n      <td>0.10230</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>15.85</td>\n      <td>23.95</td>\n      <td>103.70</td>\n      <td>782.7</td>\n      <td>0.08401</td>\n      <td>0.10020</td>\n      <td>0.09938</td>\n      <td>0.05364</td>\n      <td>0.1847</td>\n      <td>0.05338</td>\n      <td>...</td>\n      <td>27.66</td>\n      <td>112.00</td>\n      <td>876.5</td>\n      <td>0.1131</td>\n      <td>0.1924</td>\n      <td>0.2322</td>\n      <td>0.11190</td>\n      <td>0.2809</td>\n      <td>0.06287</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>13.73</td>\n      <td>22.61</td>\n      <td>93.60</td>\n      <td>578.3</td>\n      <td>0.11310</td>\n      <td>0.22930</td>\n      <td>0.21280</td>\n      <td>0.08025</td>\n      <td>0.2069</td>\n      <td>0.07682</td>\n      <td>...</td>\n      <td>32.01</td>\n      <td>108.80</td>\n      <td>697.7</td>\n      <td>0.1651</td>\n      <td>0.7725</td>\n      <td>0.6943</td>\n      <td>0.22080</td>\n      <td>0.3596</td>\n      <td>0.14310</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>14.54</td>\n      <td>27.54</td>\n      <td>96.73</td>\n      <td>658.8</td>\n      <td>0.11390</td>\n      <td>0.15950</td>\n      <td>0.16390</td>\n      <td>0.07364</td>\n      <td>0.2303</td>\n      <td>0.07077</td>\n      <td>...</td>\n      <td>37.13</td>\n      <td>124.10</td>\n      <td>943.2</td>\n      <td>0.1678</td>\n      <td>0.6577</td>\n      <td>0.7026</td>\n      <td>0.17120</td>\n      <td>0.4218</td>\n      <td>0.13410</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>14.68</td>\n      <td>20.13</td>\n      <td>94.74</td>\n      <td>684.5</td>\n      <td>0.09867</td>\n      <td>0.07200</td>\n      <td>0.07395</td>\n      <td>0.05259</td>\n      <td>0.1586</td>\n      <td>0.05922</td>\n      <td>...</td>\n      <td>30.88</td>\n      <td>123.40</td>\n      <td>1138.0</td>\n      <td>0.1464</td>\n      <td>0.1871</td>\n      <td>0.2914</td>\n      <td>0.16090</td>\n      <td>0.3029</td>\n      <td>0.08216</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16.13</td>\n      <td>20.68</td>\n      <td>108.10</td>\n      <td>798.8</td>\n      <td>0.11700</td>\n      <td>0.20220</td>\n      <td>0.17220</td>\n      <td>0.10280</td>\n      <td>0.2164</td>\n      <td>0.07356</td>\n      <td>...</td>\n      <td>31.48</td>\n      <td>136.80</td>\n      <td>1315.0</td>\n      <td>0.1789</td>\n      <td>0.4233</td>\n      <td>0.4784</td>\n      <td>0.20730</td>\n      <td>0.3706</td>\n      <td>0.11420</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19.81</td>\n      <td>22.15</td>\n      <td>130.00</td>\n      <td>1260.0</td>\n      <td>0.09831</td>\n      <td>0.10270</td>\n      <td>0.14790</td>\n      <td>0.09498</td>\n      <td>0.1582</td>\n      <td>0.05395</td>\n      <td>...</td>\n      <td>30.88</td>\n      <td>186.80</td>\n      <td>2398.0</td>\n      <td>0.1512</td>\n      <td>0.3150</td>\n      <td>0.5372</td>\n      <td>0.23880</td>\n      <td>0.2768</td>\n      <td>0.07615</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>13.54</td>\n      <td>14.36</td>\n      <td>87.46</td>\n      <td>566.3</td>\n      <td>0.09779</td>\n      <td>0.08129</td>\n      <td>0.06664</td>\n      <td>0.04781</td>\n      <td>0.1885</td>\n      <td>0.05766</td>\n      <td>...</td>\n      <td>19.26</td>\n      <td>99.70</td>\n      <td>711.2</td>\n      <td>0.1440</td>\n      <td>0.1773</td>\n      <td>0.2390</td>\n      <td>0.12880</td>\n      <td>0.2977</td>\n      <td>0.07259</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 31 columns</p>\n</div>",
            "text/plain": "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0         17.99         10.38          122.80     1001.0          0.11840   \n1         20.57         17.77          132.90     1326.0          0.08474   \n2         19.69         21.25          130.00     1203.0          0.10960   \n3         11.42         20.38           77.58      386.1          0.14250   \n4         20.29         14.34          135.10     1297.0          0.10030   \n5         12.45         15.70           82.57      477.1          0.12780   \n6         18.25         19.98          119.60     1040.0          0.09463   \n7         13.71         20.83           90.20      577.9          0.11890   \n8         13.00         21.82           87.50      519.8          0.12730   \n9         12.46         24.04           83.97      475.9          0.11860   \n10        16.02         23.24          102.70      797.8          0.08206   \n11        15.78         17.89          103.60      781.0          0.09710   \n12        19.17         24.80          132.40     1123.0          0.09740   \n13        15.85         23.95          103.70      782.7          0.08401   \n14        13.73         22.61           93.60      578.3          0.11310   \n15        14.54         27.54           96.73      658.8          0.11390   \n16        14.68         20.13           94.74      684.5          0.09867   \n17        16.13         20.68          108.10      798.8          0.11700   \n18        19.81         22.15          130.00     1260.0          0.09831   \n19        13.54         14.36           87.46      566.3          0.09779   \n\n    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0            0.27760         0.30010              0.14710         0.2419   \n1            0.07864         0.08690              0.07017         0.1812   \n2            0.15990         0.19740              0.12790         0.2069   \n3            0.28390         0.24140              0.10520         0.2597   \n4            0.13280         0.19800              0.10430         0.1809   \n5            0.17000         0.15780              0.08089         0.2087   \n6            0.10900         0.11270              0.07400         0.1794   \n7            0.16450         0.09366              0.05985         0.2196   \n8            0.19320         0.18590              0.09353         0.2350   \n9            0.23960         0.22730              0.08543         0.2030   \n10           0.06669         0.03299              0.03323         0.1528   \n11           0.12920         0.09954              0.06606         0.1842   \n12           0.24580         0.20650              0.11180         0.2397   \n13           0.10020         0.09938              0.05364         0.1847   \n14           0.22930         0.21280              0.08025         0.2069   \n15           0.15950         0.16390              0.07364         0.2303   \n16           0.07200         0.07395              0.05259         0.1586   \n17           0.20220         0.17220              0.10280         0.2164   \n18           0.10270         0.14790              0.09498         0.1582   \n19           0.08129         0.06664              0.04781         0.1885   \n\n    mean fractal dimension   ...    worst texture  worst perimeter  \\\n0                  0.07871   ...            17.33           184.60   \n1                  0.05667   ...            23.41           158.80   \n2                  0.05999   ...            25.53           152.50   \n3                  0.09744   ...            26.50            98.87   \n4                  0.05883   ...            16.67           152.20   \n5                  0.07613   ...            23.75           103.40   \n6                  0.05742   ...            27.66           153.20   \n7                  0.07451   ...            28.14           110.60   \n8                  0.07389   ...            30.73           106.20   \n9                  0.08243   ...            40.68            97.65   \n10                 0.05697   ...            33.88           123.80   \n11                 0.06082   ...            27.28           136.50   \n12                 0.07800   ...            29.94           151.70   \n13                 0.05338   ...            27.66           112.00   \n14                 0.07682   ...            32.01           108.80   \n15                 0.07077   ...            37.13           124.10   \n16                 0.05922   ...            30.88           123.40   \n17                 0.07356   ...            31.48           136.80   \n18                 0.05395   ...            30.88           186.80   \n19                 0.05766   ...            19.26            99.70   \n\n    worst area  worst smoothness  worst compactness  worst concavity  \\\n0       2019.0            0.1622             0.6656           0.7119   \n1       1956.0            0.1238             0.1866           0.2416   \n2       1709.0            0.1444             0.4245           0.4504   \n3        567.7            0.2098             0.8663           0.6869   \n4       1575.0            0.1374             0.2050           0.4000   \n5        741.6            0.1791             0.5249           0.5355   \n6       1606.0            0.1442             0.2576           0.3784   \n7        897.0            0.1654             0.3682           0.2678   \n8        739.3            0.1703             0.5401           0.5390   \n9        711.4            0.1853             1.0580           1.1050   \n10      1150.0            0.1181             0.1551           0.1459   \n11      1299.0            0.1396             0.5609           0.3965   \n12      1332.0            0.1037             0.3903           0.3639   \n13       876.5            0.1131             0.1924           0.2322   \n14       697.7            0.1651             0.7725           0.6943   \n15       943.2            0.1678             0.6577           0.7026   \n16      1138.0            0.1464             0.1871           0.2914   \n17      1315.0            0.1789             0.4233           0.4784   \n18      2398.0            0.1512             0.3150           0.5372   \n19       711.2            0.1440             0.1773           0.2390   \n\n    worst concave points  worst symmetry  worst fractal dimension  target  \n0                0.26540          0.4601                  0.11890       0  \n1                0.18600          0.2750                  0.08902       0  \n2                0.24300          0.3613                  0.08758       0  \n3                0.25750          0.6638                  0.17300       0  \n4                0.16250          0.2364                  0.07678       0  \n5                0.17410          0.3985                  0.12440       0  \n6                0.19320          0.3063                  0.08368       0  \n7                0.15560          0.3196                  0.11510       0  \n8                0.20600          0.4378                  0.10720       0  \n9                0.22100          0.4366                  0.20750       0  \n10               0.09975          0.2948                  0.08452       0  \n11               0.18100          0.3792                  0.10480       0  \n12               0.17670          0.3176                  0.10230       0  \n13               0.11190          0.2809                  0.06287       0  \n14               0.22080          0.3596                  0.14310       0  \n15               0.17120          0.4218                  0.13410       0  \n16               0.16090          0.3029                  0.08216       0  \n17               0.20730          0.3706                  0.11420       0  \n18               0.23880          0.2768                  0.07615       0  \n19               0.12880          0.2977                  0.07259       1  \n\n[20 rows x 31 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Applying our First Model with Scikit-learn: KNN\n(**k nearest neighbour**)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Splitting into Train and Test Sets"
    },
    {
      "metadata": {
        "run_control": {
          "marked": false
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    cancer_data.data,\n    cancer_data.target,\n    #stratify = cancer_data.target,\n    shuffle = True,random_state=100)",
      "execution_count": 68,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(426, 30)\n(143, 30)\n(426,)\n(143,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[y_train == 0].size",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "156"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_test[y_test == 0].size",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 71,
          "data": {
            "text/plain": "56"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Build our model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=6)   #create an instance of an object for KNeighborsClassifier class",
      "execution_count": 72,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Training/Fit our model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn.fit(X_train, y_train) # train our model by fit method",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n           weights='uniform')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Making Predictions"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Test set predictions: {}\".format(knn.predict(X_test)))",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Test set predictions: [0 1 0 1 1 1 0 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1\n 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0\n 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0\n 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Train & Test set accuracy"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Train set accuracy: {:.2f}\".format(knn.score(X_train, y_train)))\nprint(\"Test set accuracy: {:.2f}\".format(knn.score(X_test, y_test)))",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train set accuracy: 0.94\nTest set accuracy: 0.96\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Improving the KNN Performance on Cancer Dataset\n* Improve the performance of our model through feature scaling\n* Tune the hyper-parameter k of KNN to find its best value "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Improving the Model Performance"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Min Max Scalar"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Min Max Scaling scales the numeric values of a dataset by transforming them into a range between 0 and 1. The formula used is as follows:\n\nX_std = (X - X.min) / (X.max - X.min)\n\n\nX_scaled = X_std * (max - min) + min"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train_minmax_scaled = scaler.transform(X_train)\nX_test_minmax_scaled = scaler.transform(X_test)",
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn.fit(X_train_minmax_scaled, y_train)\nprint(\"Test set accuracy: {:.2f}\".format(knn.score(X_test_minmax_scaled, y_test)))\nprint(\"Train set accuracy: {:.2f}\".format(knn.score(X_train_minmax_scaled, y_train)))",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Test set accuracy: 0.96\nTrain set accuracy: 0.97\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Testing with different values of k"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_accuracy = []\ntest_accuracy = []\n\nneighbors = range(1, 11)\n\nfor n in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=n)\n    knn.fit(X_train_minmax_scaled, y_train)\n    train_accuracy.append(knn.score(X_train_minmax_scaled, y_train))\n    test_accuracy.append(knn.score(X_test_minmax_scaled, y_test))",
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(train_accuracy)\nprint(test_accuracy)",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1.0, 0.9694835680751174, 0.9859154929577465, 0.971830985915493, 0.9741784037558685, 0.9694835680751174, 0.9765258215962441, 0.9765258215962441, 0.9765258215962441, 0.9741784037558685]\n[0.972027972027972, 0.9790209790209791, 0.972027972027972, 0.965034965034965, 0.958041958041958, 0.958041958041958, 0.958041958041958, 0.958041958041958, 0.958041958041958, 0.965034965034965]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Plotting results of diffrent values of k"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.plot(neighbors, train_accuracy, label=\"train accuracy\")\nplt.plot(neighbors, test_accuracy, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"neighbors\")\nplt.legend()",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 80,
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7fcfb36a9390>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fcfb36c3518>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train_minmax_scaled, y_train)\nprint(knn.score(X_train_minmax_scaled, y_train))\nprint(knn.score(X_test_minmax_scaled, y_test))",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9859154929577465\n0.972027972027972\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(X_train_minmax_scaled, y_train)\nprint(knn.score(X_train_minmax_scaled, y_train))\nprint(knn.score(X_test_minmax_scaled, y_test))",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.971830985915493\n0.965034965034965\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train_minmax_scaled, y_train)\nprint(knn.score(X_train_minmax_scaled, y_train))\nprint(knn.score(X_test_minmax_scaled, y_test))",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9741784037558685\n0.965034965034965\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/?utm_source=linkedin.com&utm_medium=social"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Understand how the K-Nearest Neighbors (KNN) algorithm works"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "from IPython.display import IFrame    \nIFrame('https://www.saedsayad.com/k_nearest_neighbors.htm', width=1000, height=700)",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/html": "\n        <iframe\n            width=\"1000\"\n            height=\"700\"\n            src=\"https://www.saedsayad.com/k_nearest_neighbors.htm\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
            "text/plain": "<IPython.lib.display.IFrame at 0x7fcfb3676e80>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Applying our Second Model with Scikit-learn: Logistic Regression"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* we try to predict the probabilities of a target labels or classes for a specified problem\n* The formula for regression need to be adjusted"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### The Formula"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![Imgur](https://i.imgur.com/iGNsDyl.jpg)    \n<sub>source: <a href=\"https://www.biomedware.com/files/documentation/spacestat/Statistics/Multivariate_Modeling/Regression/Implementation_of_Logistic_GWR.htm\" target=\"_blank\">https://www.biomedware.com/files/documentation/spacestat/Statistics/Multivariate_Modeling/Regression/Implementation_of_Logistic_GWR.htm\n</a></sub>  \n  \n![Imgur](https://i.imgur.com/WayfUZH.png)    \n<sub>source: <a href=\"https://www.saedsayad.com/logistic_regression.htm\n\" target=\"_blank\">https://www.saedsayad.com/logistic_regression.htm\n</a></sub>  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.datasets import load_breast_cancer\ncancer_data = load_breast_cancer()",
      "execution_count": 85,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    cancer_data.data, cancer_data.target,stratify = cancer_data.target,\n    shuffle = True,random_state=144)",
      "execution_count": 86,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 87,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\nprint(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training set score: 0.962\nTest set score: 0.958\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_logreg = logreg.predict(X_test)",
      "execution_count": 89,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Evaluating classification models."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "* confusion matrix\n* precision, recall and F1 score\n* RoC curves and AUC "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p><img src=\"imgs/screenshot_20190402_013359.jpg\" alt=\"Example\" width=\"450\" height=\"220\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p><img src=\"imgs/screenshot_20190402_014409.jpg\" alt=\"Example\" width=\"450\" height=\"220\">"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\nconfusion = confusion_matrix(y_test, pred_logreg)\nprint(\"Confusion matrix:\\n{}\".format(confusion))",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Confusion matrix:\n[[48  5]\n [ 1 89]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p><img src=\"imgs/screenshot_20190402_014910.jpg\" alt=\"Example\" width=\"450\" height=\"220\">\n<p><img src=\"imgs/screenshot_20190402_014931.jpg\" alt=\"Example\" width=\"450\" height=\"220\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<p><img src=\"imgs/screenshot_20190402_015005.jpg\" alt=\"Example\" width=\"450\" height=\"220\">"
    },
    {
      "metadata": {
        "run_control": {
          "marked": false
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred_logreg,\ntarget_names=[\"malignant\", \"benign\"]))",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n  malignant       0.98      0.91      0.94        53\n     benign       0.95      0.99      0.97        90\n\navg / total       0.96      0.96      0.96       143\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score\nf1_score(y_test, pred_logreg)",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 92,
          "data": {
            "text/plain": "0.9673913043478262"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**Note:** *Evaluation depends on context*\n* **Spam filter:** high precision is important - *minimize false positive*\n* **Cancer detection:** high recall is important - *minimize false negative*"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
      "execution_count": 93,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "logreg_scaled = logreg.fit(X_train_scaled, y_train)\nprint(\"Train set accuracy: {:.2f}\".format(logreg_scaled.score(X_train_scaled, y_train)))\nprint(\"Test set accuracy: {:.2f}\".format(logreg_scaled.score(X_test_scaled, y_test)))",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train set accuracy: 0.99\nTest set accuracy: 0.97\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, logreg.decision_function(X_test))",
      "execution_count": 95,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "thresholds",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 96,
          "data": {
            "text/plain": "array([ -292.09984552,  -689.44097901,  -701.22983634,  -711.1233783 ,\n        -712.00736031,  -984.54016662,  -994.91634991,  -997.80276082,\n       -1002.82983348, -1022.96281721, -1067.12689089, -1080.62180764,\n       -1086.6301455 , -1191.99529065, -3882.06716811])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nnp.argmin(np.abs(thresholds))",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 97,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(fpr, tpr, label=\"ROC Curve\")\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR (recall)\")\nnearest_to_zero = np.argmin(np.abs(thresholds))\nplt.plot(fpr[nearest_to_zero], tpr[nearest_to_zero], 'o', markersize=10,\nlabel=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\nplt.legend(loc=4)",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 98,
          "data": {
            "text/plain": "<matplotlib.legend.Legend at 0x7fcfb36b00f0>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7fcfb36b0080>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import roc_auc_score\nlogreg_auc = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\nprint(\"AUC for Logreg: {:.3f}\".format(logreg_auc))",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": "AUC for Logreg: 0.699\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n  np.exp(prob, prob)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pred_logreg_scaled = logreg_scaled.predict(X_test_scaled)",
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "f1_score(y_test, pred_logreg_scaled)",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 101,
          "data": {
            "text/plain": "0.978021978021978"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "confusion = confusion_matrix(y_test, pred_logreg_scaled)\nprint(\"Confusion matrix:\\n{}\".format(confusion))",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Confusion matrix:\n[[50  3]\n [ 1 89]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}